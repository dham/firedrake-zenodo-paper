\documentclass[a4paper,11pt]{article}

\usepackage[margin=2.5cm]{geometry}
\usepackage{palatino}

\usepackage[doi=true,url=true,style=authoryear,dashed=false,firstinits=true,maxnames=2,maxbibnames=99,backend=biber]{biblatex}
\renewbibmacro{in:}{%
  \ifentrytype{article}{}{%
  \printtext{\bibstring{in}\intitlepunct}}}

\bibliography{bibliography}

\begin{document}

\title{Provenance tracking for scientific software toolchains through on-demand release and archiving}

\author{David A. Ham\\Department of Mathematics, Imperial College London}

\maketitle

\section*{Abstract}

\section{Introduction}

There is an emerging consensus that published computational science results
must be backed by a provenance chain tying results to the exact versions of
input data and the code which generated them. There is also now an
impressive range of web services devoted to revision control of software,
and the archiving in citable form of both software and input data.  However,
it is also observably the case that very many papers are published which do
not adhere to these high standards of transparency and reproducibility. It
therefore seems apparent that many scientists who rely on
computations to produce results are sufficiently aware of, or see the need
to provide suffucient provenance information for their results.

Part of the solution to this problem is procedural: as the policies of
journals and funders evolve, and as reviewer expectations increase, it is to
be hoped that the publication of provenance chains will become more
pervasive. However it is also the case that publishing the provenance chain
for many current scientific computation workflows currently requires effort and
sometimes technical knowledge beyond that which many scientists are willing
and/or able to deploy. 

The challenge, therefore, for the authors of the tools in those scientific
workflows is to provide mechanisms which make the publication of provenance
chains as easy as possible for users of those tools.

This paper examines why the reality of complex and rapidly evolving
toolchains makes recording provenance information complicated. It then
describes the particular approach employed by the Firedrake project as an
example of the steps which toolchain authors can adopt to
leverage the existing web services to provide close to automatic provenance
chain recording.

\section{Related work}

% GitHub Zenodo integration

\section{The provenance challenge for complex tool chains}

The simplest computational workflows are well supported by the range of
currently available tools. If a scientist has a data set, and writes some
code which acts on that data set then he or she can host the code on an open
platform such as GitHub or BitBucket, and archive both the code and the data
on a platform such as Zenodo or Figshare. For completeness, the scientist
should preferably also list the version of the compilers and/or interpreters
employed to run the code. Thanks in large part to the high quality of
software engineering and interface design on behalf of the web services,
this workflow enables a scientist to achieve best practice for very little
effort. 

However, much computational science depends on third party scientific
packages such as simulation tools, equation solvers and data analysis
libraries. In the first instance, this appears to present little difficulty:
the user simply cites the version number of the packages which they
employed. The reality of computational science, however, is that those
packages themselves are frequently in active development. The scientist will
often have employed development versions of the package obtained directly
from the package revision control system. Often these packages themselves
will have dependencies and the scientist may well be using development
versions of those as well. From a scientific correctness point of view, this
presents no additional problems so long as the package authors verify and
validate their development versions using a continuous integration
system \parencite[see, for example][]{Farrell2010}. However from a
provenance perspective, this is problematic. As noted above, citing git
hashes or other version control identifiers is not sufficient. At the same
time, manually uploading the correct versions of multiple external
dependencies to an archive requires the tedious and error-prone task of
correctly entering third party metadata. Using the GitHub Zenodo integration to
accomplish this, even assuming that the packages are already managed under
git, requires the user to fork the original repository, and then link their
Zenodo account to it before creating a release. The level of effort and
technical knowledge this requires seems entirely likely to deter scientists
from undertaking this process.

\section{Requirements for a provenance solution}

On the basis of the above, we can specify some criteria which are necessary
for effective provenance tracking:
\begin{enumerate}
\item The effort required of scientist users must be minimal.
\item The expertise required of scientist users must be minimal.
\item The exact versions of software employed must be recorded and archived
  in a durable manner.
\item The process should minimise the possibilities for human error.
\end{enumerate}

\section{Firedrake GitHub and Zenodo integration}

Firedrake is a system for the automated solution of partial differential
equations by the finite element method \parencite{Rathgeber2015}. Firedrake
works by composing together a number of in-house and third party
implementations of software abstractions for different parts of the
simulation process. The result is a programmable interface under which users
write high level mathematical code to create simulation software.

Firedrake has a number of features which make it an exemplar of a complex
toolchain which poses difficulties for current approaches to provenance
tracking. First, Firedrake is under constant development, employing
continuous integration to demonstrate test coverage of the master branch and
all feature branches. There are no fixed releases. Instead, the install system
facilitates users following the developments of the master branch. Firedrake
has seven specialist version controlled dependencies, in addition to released
versions of conventional dependencies such as compilers, MPI, BLAS and
LAPack. This means that the version of Firedrake employed in a particular
computational experiment is in fact a bespoke combination of the state of
eight GitHub repositories. How, then, should a user of Firedrake archive and
cite the version of this software used in a particular numerical experiment?

At first sight, the answer to this problem is the existing GitHub
Zenodo integration. However, two limitations of this approach make it
unsuitable. First, minting a DOI from a GitHub repository using Zenodo
requires write access to the GitHub repository in order to create the
release which is to be archived. Users of software packages do not usually
have this access, and the alternative of the user creating and maintaining
their own GitHub forks merely to facilitate DOI creation fails the minimal
effort requirement. Second, the mere effort of manually creating releases of the
exactly correct versions of eight repositories fails the effort and human
error tests, and quite possibly the expertise test too.

\subsection{Firedrake-zenodo}

Conversely, for a small one-time investment of effort, the developers of a
complex system such as Firedrake can deliver a system which fulfills all the
requirements. 

\section{Provenance vs credit}

The DOIs created through the process described here are intended to be cited
exactly once: by a paper reporting a set of numerical simulations. Given
that citation counts are widely used to rate the siginificance of scientific
outputs, this makes these DOIs entirely unsuitable as a mechanism for giving
credit to the developers of Firedrake or its dependencies.

\section{Limitations of this approach}

\subsection{Untracked upstream dependencies}

\subsection{Configuration data}

\subsection{Users' own code and data}


\printbibliography

\end{document}
